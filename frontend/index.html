<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Voice Recorder with Timer & Playback</title>
  <style>
    body { font-family: sans-serif; padding: 1rem; }
    canvas { border: 1px solid #ccc; background: #222; width: 100%; height: 100px; }
    button { margin: 8px 10px 0 0; padding: 10px 18px; font-size: 1rem; }
    #status, #timerText { margin-top: 10px; font-weight: bold; }

    #circleTimerContainer {
      position: relative;
      width: 120px;
      height: 120px;
      margin: 10px 0;
    }
    #circleTimerSvg {
      transform: rotate(-90deg);
    }
    #timerText {
      position: absolute;
      top: 35px;
      left: 0;
      right: 0;
      text-align: center;
      font-size: 1.4rem;
    }

    .highlight {
      font-weight: bold;
      background: linear-gradient(90deg, #00c6ff, #0072ff);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      animation: shimmer 3s infinite;
    }

    .accent {
      background: linear-gradient(90deg, #f7971e, #ffd200);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      animation: shimmer 3s infinite;
    }

    .score {
      background: linear-gradient(90deg, #00b09b, #96c93d);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      animation: shimmer 3s infinite;
    }

    @keyframes shimmer {
      0% { filter: brightness(1); }
      50% { filter: brightness(1.5); }
      100% { filter: brightness(1); }
    }

    #stepMessages {
      margin-top: 12px;
      font-weight: bold;
      color: #555;
      opacity: 0;
      transition: opacity 0.5s;
    }
  </style>
</head>
<body>

<h2>üéôÔ∏è 60-Second Voice Recorder</h2>

<canvas id="waveform"></canvas>

<div id="circleTimerContainer">
  <svg id="circleTimerSvg" width="120" height="120">
    <circle cx="60" cy="60" r="54" stroke="#eee" stroke-width="6" fill="none"/>
    <circle id="progressCircle" cx="60" cy="60" r="54" stroke="#4caf50" stroke-width="6" fill="none" stroke-dasharray="339.29" stroke-dashoffset="0"/>
  </svg>
  <div id="timerText">60</div>
</div>

<div>
  <button id="startBtn">Start</button>
  <button id="pauseResumeBtn" disabled>Pause</button>
  <button id="stopBtn" disabled>Stop</button>
  <button id="restartBtn" disabled>Restart</button>
  <button id="playBtn" disabled>Play</button>
</div>

<div id="stepMessages"></div>
<div id="status"></div>

<script>
(async () => {
  const startBtn = document.getElementById('startBtn');
  const pauseResumeBtn = document.getElementById('pauseResumeBtn');
  const stopBtn = document.getElementById('stopBtn');
  const restartBtn = document.getElementById('restartBtn');
  const playBtn = document.getElementById('playBtn');
  const status = document.getElementById('status');
  const timerText = document.getElementById('timerText');
  const progressCircle = document.getElementById('progressCircle');
  const stepMessages = document.getElementById('stepMessages');
  const canvas = document.getElementById('waveform');
  const ctx = canvas.getContext('2d');
  canvas.width = canvas.clientWidth;
  canvas.height = canvas.clientHeight;

  const MAX_TIME = 60;
  const FULL_DASH = 2 * Math.PI * 54;
  progressCircle.setAttribute("stroke-dasharray", FULL_DASH);
  progressCircle.setAttribute("stroke-dashoffset", "0");

  let mediaRecorder, stream, audioContext, analyser, sourceNode, animationId;
  let audioChunks = [];
  let timerId, countdown = MAX_TIME;
  let isPaused = false;
  let blobURL = null;
  let messageIntervalId = null;

  const stepMsgs = [
    "üó£Ô∏è Detecting speech patterns...",
    "üéØ Measuring speech accuracy...",
    "üìä Extracting features...",
    "üõ†Ô∏è Refining analysis...",
    "üìà Calculating confidence scores...",
    "üßæ Summarizing speech insights..."
  ];

  function startStepMessageLoop() {
    let i = 0;
    stepMessages.textContent = stepMsgs[i];
    stepMessages.style.opacity = 1;

    messageIntervalId = setInterval(() => {
      i = (i + 1) % stepMsgs.length;
      stepMessages.style.opacity = 0;
      setTimeout(() => {
        stepMessages.textContent = stepMsgs[i];
        stepMessages.style.opacity = 1;
      }, 300);
    }, 2000);
  }

  function stopStepMessageLoop() {
    clearInterval(messageIntervalId);
    stepMessages.style.opacity = 0;
    messageIntervalId = null;
  }

  function drawWaveform(timestamp) {
    if (!analyser) return;
    const FRAME_INTERVAL = 1000 / 30;
    if (timestamp - lastFrame < FRAME_INTERVAL) {
      animationId = requestAnimationFrame(drawWaveform);
      return;
    }
    lastFrame = timestamp;

    const bufferLength = analyser.fftSize;
    const dataArray = new Uint8Array(bufferLength);
    analyser.getByteTimeDomainData(dataArray);

    ctx.fillStyle = '#222';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    ctx.strokeStyle = '#0f0';
    ctx.lineWidth = 2;
    ctx.beginPath();
    const sliceWidth = canvas.width / bufferLength;
    let x = 0;
    for (let i = 0; i < bufferLength; i++) {
      const v = dataArray[i] / 128.0;
      const y = v * canvas.height / 2;
      i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
      x += sliceWidth;
    }
    ctx.lineTo(canvas.width, canvas.height / 2);
    ctx.stroke();

    animationId = requestAnimationFrame(drawWaveform);
  }

  function updateTimerDisplay(secondsLeft) {
    timerText.textContent = secondsLeft;
    const progress = FULL_DASH * (secondsLeft / MAX_TIME);
    progressCircle.setAttribute("stroke-dashoffset", FULL_DASH - progress);
  }

  function startCountdown() {
    countdown = MAX_TIME;
    updateTimerDisplay(countdown);
    timerId = setInterval(() => {
      if (!isPaused && countdown > 0) {
        countdown--;
        updateTimerDisplay(countdown);
        if (countdown === 0) {
          clearInterval(timerId);
          if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
            status.textContent = 'Auto stopped at 60s.';
          }
        }
      }
    }, 1000);
  }

  function stopCountdown() {
    clearInterval(timerId);
  }

  function resetUI() {
    startBtn.disabled = false;
    pauseResumeBtn.disabled = true;
    stopBtn.disabled = true;
    restartBtn.disabled = true;
    playBtn.disabled = !blobURL;
    pauseResumeBtn.textContent = 'Pause';
    status.textContent = '';
    stepMessages.textContent = '';
    stepMessages.style.opacity = 0;
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    updateTimerDisplay(MAX_TIME);
    isPaused = false;
    audioChunks = [];
    if (animationId) cancelAnimationFrame(animationId);
    if (stream) stream.getTracks().forEach(t => t.stop());
    stopStepMessageLoop();
  }

  async function startRecording() {
    if (mediaRecorder && mediaRecorder.state === 'recording') return;

    try {
      stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    } catch (e) {
      alert('Microphone error: ' + e.message);
      return;
    }

    audioChunks = [];
    audioContext = new AudioContext();
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    sourceNode = audioContext.createMediaStreamSource(stream);
    sourceNode.connect(analyser);

    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

    mediaRecorder.ondataavailable = e => {
      if (e.data.size > 0) audioChunks.push(e.data);
    };

    mediaRecorder.onstop = async () => {
      stopCountdown();
      cancelAnimationFrame(animationId);
      sourceNode.disconnect();
      analyser.disconnect();
      stream.getTracks().forEach(t => t.stop());

      const blob = new Blob(audioChunks, { type: 'audio/webm' });
      blobURL = URL.createObjectURL(blob);
      playBtn.disabled = false;

      status.textContent = '';
      startStepMessageLoop();

      const formData = new FormData();
      formData.append('file', blob, 'recording.webm');

      try {
        const res = await fetch('http://127.0.0.1:8000/V1/analyze/', {
          method: 'POST',
          body: formData,
        });

        stopStepMessageLoop();

        if (res.ok) {
          const data = await res.json();
          if (data.lang !== "English") {
            status.innerHTML = `You are speaking ${data.lang}, Please speak in English.`;
          } else {
            status.innerHTML = `
              ‚úÖ Upload Successful<br>
              <strong><span class="highlight">Transcription: </strong> ${data.transcription}</span><br>
              <strong><span class="accent">Accent: </strong> ${data.accent}</span><br>
              <strong><span class="score">Accent Score: </strong> ${data.accent_score}%</span><br>
              <strong>Filler Count: </strong> ${data.filler_count}</span><br>
              <strong>Filler Words: </strong> ${data.filler_words}</span><br>
              <strong>WPM: </strong> ${data.wpm}<br>
              <strong>Duration: </strong> ${data.duration} secs</span>`;
          }
        } else {
          const error = await res.json();
          status.textContent = `‚ùå ${error.error || 'Upload failed'}`;
        }
      } catch (err) {
        stopStepMessageLoop();
        status.textContent = `‚ùå Error: ${err.message}`;
      }
    };

    mediaRecorder.start();
    startCountdown();
    animationId = requestAnimationFrame(drawWaveform);
    startBtn.disabled = true;
    pauseResumeBtn.disabled = false;
    stopBtn.disabled = false;
    restartBtn.disabled = true;
    playBtn.disabled = true;
    status.textContent = 'Recording...';
  }

  function pauseRecording() {
    mediaRecorder.pause();
    isPaused = true;
    pauseResumeBtn.textContent = 'Resume';
    status.textContent = 'Paused';
  }

  function resumeRecording() {
    mediaRecorder.resume();
    isPaused = false;
    pauseResumeBtn.textContent = 'Pause';
    status.textContent = 'Recording...';
  }

  function stopRecording() {
    if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
      mediaRecorder.stop();
      stopBtn.disabled = true;
      pauseResumeBtn.disabled = true;
      restartBtn.disabled = false;
      stopCountdown();
    }
  }

  function restartRecording() {
    resetUI();
    startRecording();
  }

  function playRecording() {
    if (!blobURL) return;
    const audio = new Audio(blobURL);
    audio.play();
  }

  startBtn.onclick = startRecording;
  pauseResumeBtn.onclick = () => isPaused ? resumeRecording() : pauseRecording();
  stopBtn.onclick = stopRecording;
  restartBtn.onclick = restartRecording;
  playBtn.onclick = playRecording;

  let lastFrame = 0;
  resetUI();
})();
</script>

</body>
</html>
